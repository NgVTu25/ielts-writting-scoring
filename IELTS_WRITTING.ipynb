{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "461519c8"
      },
      "source": [
        "# üìù IELTS Essay Scorer with LLM\n",
        "\n",
        "ƒê√¢y l√† m·ªôt s·ªï ghi ch√©p Google Colab tri·ªÉn khai m·ªôt API ch·∫•m ƒëi·ªÉm b√†i lu·∫≠n IELTS (Task 2) s·ª≠ d·ª•ng m√¥ h√¨nh Ng√¥n ng·ªØ l·ªõn (LLM) ƒë∆∞·ª£c tinh ch·ªânh t·ª´ Hugging Face. API n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° c√°c b√†i lu·∫≠n d·ª±a tr√™n c√°c ti√™u ch√≠ ch·∫•m ƒëi·ªÉm ch√≠nh th·ª©c c·ªßa IELTS: Task Achievement, Coherence and Cohesion, Lexical Resource, v√† Grammatical Range and Accuracy.\n",
        "\n",
        "## ‚ú® T√≠nh nƒÉng\n",
        "\n",
        "- **ƒê√°nh gi√° chi ti·∫øt theo ti√™u ch√≠ IELTS**: Cung c·∫•p ph·∫£n h·ªìi chuy√™n s√¢u cho t·ª´ng ti√™u ch√≠ ch·∫•m ƒëi·ªÉm IELTS.\n",
        "- **Tr√≠ch d·∫´n v√† v√≠ d·ª• c·ª• th·ªÉ**: ƒê√°nh gi√° bao g·ªìm c√°c tr√≠ch d·∫´n tr·ª±c ti·∫øp t·ª´ b√†i lu·∫≠n c·ªßa th√≠ sinh ƒë·ªÉ minh h·ªça ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu.\n",
        "- **ƒê·ªÅ xu·∫•t band ƒëi·ªÉm**: ƒê∆∞a ra c√°c band ƒëi·ªÉm ∆∞·ªõc t√≠nh cho t·ª´ng ti√™u ch√≠ v√† t·ªïng th·ªÉ.\n",
        "- **S·ª≠a l·ªói ng·ªØ ph√°p v√† t·ª´ v·ª±ng**: X√°c ƒë·ªãnh v√† ƒë∆∞a ra s·ª≠a l·ªói cho c√°c l·ªói ph·ªï bi·∫øn.\n",
        "- **Ph·∫£n h·ªìi h√†nh ƒë·ªông**: Cung c·∫•p t√≥m t·∫Øt, ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu c·ª• th·ªÉ v·ªõi c√°c g·ª£i √Ω c·∫£i thi·ªán.\n",
        "- **Tri·ªÉn khai API v·ªõi Flask v√† ngrok**: Cho ph√©p truy c·∫≠p d·ªãch v·ª• ch·∫•m ƒëi·ªÉm th√¥ng qua m·ªôt API c√¥ng khai.\n",
        "- **X·ª≠ l√Ω s·ªë l∆∞·ª£ng t·ª´**: T·ª± ƒë·ªông ch·∫•m 0 ƒëi·ªÉm cho b√†i lu·∫≠n d∆∞·ªõi 100 t·ª´ v√† √°p d·ª•ng tr·ª´ ƒëi·ªÉm cho b√†i lu·∫≠n t·ª´ 100 ƒë·∫øn 249 t·ª´.\n",
        "\n",
        "## üöÄ B·∫Øt ƒë·∫ßu\n",
        "\n",
        "### 1. Chu·∫©n b·ªã m√¥i tr∆∞·ªùng Colab\n",
        "\n",
        "Ch·∫°y t·∫•t c·∫£ c√°c √¥ m√£ trong s·ªï ghi ch√©p theo th·ª© t·ª±. S·ªï ghi ch√©p s·∫Ω t·ª± ƒë·ªông:\n",
        "\n",
        "- C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt (`bitsandbytes`, `flask`, `pyngrok`, `transformers`, `accelerate`, `flask_cors`, `peft`, `sentencepiece`).\n",
        "- T·∫£i m√¥ h√¨nh LLM v√† tokenizer t·ª´ Hugging Face (`NGVT21/IELTS_Writing`).\n",
        "- Kh·ªüi t·∫°o ·ª©ng d·ª•ng Flask.\n",
        "- Thi·∫øt l·∫≠p ngrok tunnel ƒë·ªÉ t·∫°o m·ªôt URL c√¥ng khai cho API.\n",
        "\n",
        "### 2. Thi·∫øt l·∫≠p ngrok Auth Token\n",
        "\n",
        "ƒê·ªÉ s·ª≠ d·ª•ng `ngrok`, b·∫°n c·∫ßn c√≥ m·ªôt Auth Token. Vui l√≤ng truy c·∫≠p [trang web ngrok](https://dashboard.ngrok.com/get-started/your-authtoken), ƒëƒÉng k√Ω/ƒëƒÉng nh·∫≠p v√† sao ch√©p Auth Token c·ªßa b·∫°n. Sau ƒë√≥, d√°n n√≥ v√†o d√≤ng sau trong √¥ m√£ c√†i ƒë·∫∑t:\n",
        "\n",
        "```python\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN_HERE\")\n",
        "```\n",
        "\n",
        "B·∫°n c≈©ng c√≥ th·ªÉ l∆∞u token v√†o Colab Secrets ƒë·ªÉ s·ª≠ d·ª•ng l·∫°i.\n",
        "\n",
        "### 3. S·ª≠ d·ª•ng API\n",
        "\n",
        "Sau khi t·∫•t c·∫£ c√°c √¥ m√£ ƒë√£ ch·∫°y th√†nh c√¥ng, b·∫°n s·∫Ω th·∫•y m·ªôt URL c√¥ng khai hi·ªÉn th·ªã trong output cu·ªëi c√πng, v√≠ d·ª•:\n",
        "\n",
        "```\n",
        "üåç URL C√¥ng khai (Public URL): https://your-unique-id.ngrok-free.dev\n",
        "üëâ Endpoint ƒë·ªÉ ch·∫•m ƒëi·ªÉm: https://your-unique-id.ngrok-free.dev/score\n",
        "```\n",
        "\n",
        "B·∫°n c√≥ th·ªÉ g·ª≠i y√™u c·∫ßu POST ƒë·∫øn endpoint `/score` n√†y v·ªõi payload JSON ch·ª©a `task` v√† `essay`.\n",
        "\n",
        "**Endpoint**: `/score`\n",
        "**Ph∆∞∆°ng th·ª©c**: `POST`\n",
        "**Content-Type**: `application/json`\n",
        "\n",
        "**V√≠ d·ª• v·ªÅ Payload (JSON Request Body)**:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"task\": \"Some people think that the government should ban dangerous sports, while others think that people should be free to choose any sport activities. Discuss both views and give your own opinion.\",\n",
        "  \"essay\": \"Dangerous sports like skydiving and rock climbing have become increasingly popular. Some argue for a ban due to the inherent risks, while others champion individual freedom. This essay will discuss both perspectives and present a balanced view.\"\n",
        "}\n",
        "```\n",
        "\n",
        "**V√≠ d·ª• v·ªÅ Ph·∫£n h·ªìi (JSON Response)**:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"coherence_cohesion\": {\n",
        "    \"assessment\": \"...\",\n",
        "    \"suggested_band_score\": \"...\"\n",
        "  },\n",
        "  \"feedback\": {\n",
        "    \"strengths\": [\n",
        "      \"...\"\n",
        "    ],\n",
        "    \"summary\": \"...\",\n",
        "    \"weaknesses\": [\n",
        "      \"...\"\n",
        "    ]\n",
        "  },\n",
        "  \"grammatical_range_accuracy\": {\n",
        "    \"assessment\": \"...\",\n",
        "    \"examples_of_complex_structures\": [\n",
        "      \"...\"\n",
        "    ],\n",
        "    \"mistakes_rectified\": [\n",
        "      {\n",
        "        \"correction\": \"...\",\n",
        "        \"original\": \"...\"\n",
        "      }\n",
        "    ],\n",
        "    \"suggested_band_score\": \"...\"\n",
        "  },\n",
        "  \"lexical_resource\": {\n",
        "    \"assessment\": \"...\",\n",
        "    \"examples_of_good_vocabulary\": [\n",
        "      \"...\"\n",
        "    ],\n",
        "    \"mistakes_rectified\": [\n",
        "      {\n",
        "        \"correction\": \"...\",\n",
        "        \"original\": \"...\"\n",
        "      }\n",
        "    ],\n",
        "    \"suggested_band_score\": \"...\"\n",
        "  },\n",
        "  \"overall_band_score\": \"...\",\n",
        "  \"task_achievement\": {\n",
        "    \"assessment\": \"...\",\n",
        "    \"suggested_band_score\": \"...\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "## üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng\n",
        "\n",
        "- **Python**: Ng√¥n ng·ªØ l·∫≠p tr√¨nh ch√≠nh.\n",
        "- **Flask**: Framework web ƒë·ªÉ x√¢y d·ª±ng API.\n",
        "- **Pyngrok**: Th∆∞ vi·ªán Python ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi ngrok v√† t·∫°o public URL.\n",
        "- **Hugging Face Transformers**: Th∆∞ vi·ªán ƒë·ªÉ t·∫£i v√† s·ª≠ d·ª•ng m√¥ h√¨nh LLM.\n",
        "- **Accelerate & BitsAndBytes**: ƒê·ªÉ t·ªëi ∆∞u h√≥a vi·ªác s·ª≠ d·ª•ng GPU v√† ch·∫°y m√¥ h√¨nh l·ªõn tr√™n ph·∫ßn c·ª©ng h·∫°n ch·∫ø (Colab T4).\n",
        "- **PyTorch**: Framework deep learning c∆° b·∫£n.\n",
        "- **CORS**: ƒê·ªÉ x·ª≠ l√Ω c√°c y√™u c·∫ßu cross-origin cho API.\n",
        "\n",
        "## ‚ö†Ô∏è L∆∞u √Ω\n",
        "\n",
        "- **Th·ªùi gian kh·ªüi ƒë·ªông**: Vi·ªác t·∫£i m√¥ h√¨nh c√≥ th·ªÉ m·∫•t m·ªôt ch√∫t th·ªùi gian t√πy thu·ªôc v√†o t·ªëc ƒë·ªô m·∫°ng.\n",
        "- **Gi·ªõi h·∫°n t√†i nguy√™n Colab**: M√¥ h√¨nh n√†y ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ ch·∫°y hi·ªáu qu·∫£ tr√™n GPU Colab T4 th√¥ng qua l∆∞·ª£ng t·ª≠ h√≥a 4-bit. Hi·ªáu su·∫•t c√≥ th·ªÉ thay ƒë·ªïi.\n",
        "- **ƒê·ªô ch√≠nh x√°c c·ªßa ngrok URL**: URL c√¥ng khai c·ªßa ngrok l√† t·∫°m th·ªùi v√† s·∫Ω thay ƒë·ªïi m·ªói khi b·∫°n ch·∫°y l·∫°i s·ªï ghi ch√©p (ho·∫∑c ngrok tunnel b·ªã ng·∫Øt k·∫øt n·ªëi).\n",
        "- **Rule ch·∫•m ƒëi·ªÉm**:\n",
        "    - B√†i lu·∫≠n d∆∞·ªõi 100 t·ª´ s·∫Ω nh·∫≠n 0 ƒëi·ªÉm.\n",
        "    - B√†i lu·∫≠n t·ª´ 100 ƒë·∫øn 249 t·ª´ s·∫Ω b·ªã tr·ª´ ƒëi·ªÉm theo c√¥ng th·ª©c: 1 ƒëi·ªÉm cho m·ªói 20 t·ª´ thi·∫øu so v·ªõi 150 t·ª´, t·ªëi ƒëa 3 ƒëi·ªÉm tr·ª´."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of-t17ZC7wEa",
        "outputId": "7ad12fd0-1abc-453f-e4b7-48e51d1f1787"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒê√£ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt.\n",
            "‚è≥ ƒêang t·∫£i m√¥ h√¨nh t·ª´ Hugging Face: NGVT21/IELTS_Writing...\n",
            "Qu√° tr√¨nh n√†y ph·ª• thu·ªôc v√†o t·ªëc ƒë·ªô m·∫°ng Colab...\n"
          ]
        }
      ],
      "source": [
        "# --- 0. C√ÄI ƒê·∫∂T C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT ---\n",
        "# Ensure bitsandbytes is up-to-date and installed correctly for 4-bit quantization.\n",
        "# This often requires a runtime restart after installation in Colab if issues persist.\n",
        "!pip install -U bitsandbytes --quiet\n",
        "!pip install flask pyngrok transformers accelerate flask_cors peft sentencepiece --quiet\n",
        "print(\"ƒê√£ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt.\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import traceback\n",
        "import requests\n",
        "from threading import Thread\n",
        "# from google.colab import drive # Kh√¥ng c·∫ßn mount Drive n·ªØa\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from flask_cors import CORS\n",
        "\n",
        "# T·∫Øt c·∫£nh b√°o tokenizer\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# --- 1. C·∫§U H√åNH M√î H√åNH T·ª™ HUGGING FACE ---\n",
        "# Link g·ªëc: https://huggingface.co/NGVT21/IELTS_Writing/tree/main\n",
        "# Model ID ch·ªâ l·∫•y ph·∫ßn t√™n user/repo\n",
        "MODEL_ID = \"NGVT21/IELTS_Writing\"\n",
        "\n",
        "# Config 4-bit (ƒë·ªÉ ch·∫°y m∆∞·ª£t tr√™n Colab T4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# --- 2. T·∫¢I M√î H√åNH V√Ä TOKENIZER ---\n",
        "print(f\"‚è≥ ƒêang t·∫£i m√¥ h√¨nh t·ª´ Hugging Face: {MODEL_ID}...\")\n",
        "print(\"Qu√° tr√¨nh n√†y ph·ª• thu·ªôc v√†o t·ªëc ƒë·ªô m·∫°ng Colab...\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"cuda\",\n",
        "        torch_dtype=torch.float16,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "\n",
        "    print(f\"‚úÖ T·∫£i m√¥ h√¨nh {MODEL_ID} th√†nh c√¥ng!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}\")\n",
        "    print(\"Vui l√≤ng ki·ªÉm tra l·∫°i t√™n repo Hugging Face ho·∫∑c quy·ªÅn truy c·∫≠p (n·∫øu l√† private repo).\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "# --- 3. ƒê·ªäNH NGHƒ®A PROMPT CH·∫§M ƒêI·ªÇM ---\n",
        "PROMPT = \"\"\"\n",
        "You are required to evaluate an IELTS Writing Task 2 essay with the precision and insight of a **senior IELTS examiner**. Your analysis must be **extremely detailed, evidence-based, and include direct quotes** from the essay wherever relevant. Focus on both strengths and weaknesses, with actionable suggestions.\n",
        "\n",
        "## Task Achievement:\n",
        "- Provide a **comprehensive analysis** of how the candidate addressed the essay question.\n",
        "- **Quote multiple specific phrases or sentences** from the essay to justify each point.\n",
        "- Evaluate clarity, coherence, relevance of ideas, depth of argument, and whether the candidate fully answered all parts of the task.\n",
        "- Identify **any missing elements** or underdeveloped points.\n",
        "- Suggested Band Score (Task Achievement): [Insert Score]\n",
        "\n",
        "## Coherence and Cohesion:\n",
        "- Examine **paragraph structure, topic sentences, and logical progression**.\n",
        "- Evaluate the use of **linking devices** and their appropriateness, variety, and effectiveness (e.g., 'Furthermore', 'In contrast', 'As a result').\n",
        "- Identify **breaks in flow, abrupt transitions, or repetitive connectors**, and quote examples.\n",
        "- Suggested Band Score (Coherence and Cohesion): [Insert Score]\n",
        "\n",
        "## Lexical Resource (Vocabulary):\n",
        "- Assess **range, precision, sophistication, and appropriateness** of vocabulary.\n",
        "- Identify **at least 5 specific vocabulary errors** (misuse, awkward phrasing, or collocation issues) and provide corrections.\n",
        "- Highlight **5+ examples of impressive or less common vocabulary** used effectively.\n",
        "- Suggest strategies for expanding vocabulary where needed.\n",
        "- Suggested Band Score (Lexical Resource): [Insert Score]\n",
        "\n",
        "## Grammatical Range and Accuracy:\n",
        "- Evaluate **sentence variety and complexity**, including simple, compound, and complex sentences.\n",
        "- Identify **at least 5 grammatical errors** (tense, subject-verb agreement, article usage, word order, punctuation) and provide corrections.\n",
        "- Highlight examples of **successful complex structures** and effective sentence patterns.\n",
        "- Suggested Band Score (Grammatical Range and Accuracy): [Insert Score]\n",
        "\n",
        "## Overall Band Score:\n",
        "- Provide an overall band score reflecting **holistic performance** across all criteria.\n",
        "- Suggested Overall Band Score: [Insert Score]\n",
        "\n",
        "## Feedback and Additional Comments:\n",
        "- Provide a **detailed, actionable summary** of overall performance.\n",
        "- Clearly list **Top 3 Strengths** of the essay with justification and examples.\n",
        "- Clearly list **Top 3 Weaknesses**, explaining **how to improve each one** with examples.\n",
        "- Optionally, suggest exercises or strategies to address weaknesses.\n",
        "\n",
        "Task:\n",
        "{task}\n",
        "\n",
        "Essay:\n",
        "{essay}\n",
        "\n",
        "Return output as a **valid JSON object only**. Do not repeat the essay or instructions. Do not include explanations outside the JSON.\n",
        "\n",
        "JSON format:\n",
        "{{\n",
        "  \"task_achievement\": {{\n",
        "    \"assessment\": \"<Detailed assessment with quotes from essay>\",\n",
        "    \"suggested_band_score\": \"<0-9>\"\n",
        "  }},\n",
        "  \"coherence_cohesion\": {{\n",
        "    \"assessment\": \"<Detailed assessment of paragraph structure, linking devices, logical flow with examples>\",\n",
        "    \"suggested_band_score\": \"<0-9>\"\n",
        "  }},\n",
        "  \"lexical_resource\": {{\n",
        "    \"assessment\": \"<Assessment of vocabulary range, sophistication, appropriateness, with examples of good usage>\",\n",
        "    \"mistakes_rectified\": [\n",
        "      {{\"original\": \"<mistake 1>\", \"correction\": \"<corrected version 1>\"}},\n",
        "      {{\"original\": \"<mistake 2>\", \"correction\": \"<corrected version 2>\"}},\n",
        "      {{\"original\": \"<mistake 3>\", \"correction\": \"<corrected version 3>\"}},\n",
        "      {{\"original\": \"<mistake 4>\", \"correction\": \"<corrected version 4>\"}},\n",
        "      {{\"original\": \"<mistake 5>\", \"correction\": \"<corrected version 5>\"}}\n",
        "    ],\n",
        "    \"examples_of_good_vocabulary\": [\n",
        "      \"<Good vocabulary 1>\",\n",
        "      \"<Good vocabulary 2>\",\n",
        "      \"<Good vocabulary 3>\",\n",
        "      \"<Good vocabulary 4>\",\n",
        "      \"<Good vocabulary 5>\"\n",
        "    ],\n",
        "    \"suggested_band_score\": \"<0-9>\"\n",
        "  }},\n",
        "  \"grammatical_range_accuracy\": {{\n",
        "    \"assessment\": \"<Detailed assessment of sentence structures with examples>\",\n",
        "    \"mistakes_rectified\": [\n",
        "      {{\"original\": \"<mistake 1>\", \"correction\": \"<corrected version 1>\"}},\n",
        "      {{\"original\": \"<mistake 2>\", \"correction\": \"<corrected version 2>\"}},\n",
        "      {{\"original\": \"<mistake 3>\", \"correction\": \"<corrected version 3>\"}},\n",
        "      {{\"original\": \"<mistake 4>\", \"correction\": \"<corrected version 4>\"}},\n",
        "      {{\"original\": \"<mistake 5>\", \"correction\": \"<corrected version 5>\"}}\n",
        "    ],\n",
        "    \"examples_of_complex_structures\": [\n",
        "      \"<Complex sentence example 1>\",\n",
        "      \"<Complex sentence example 2>\",\n",
        "      \"<Complex sentence example 3>\"\n",
        "    ],\n",
        "    \"suggested_band_score\": \"<0-9>\"\n",
        "  }},\n",
        "  \"overall_band_score\": \"<0-9>\",\n",
        "  \"feedback\": {{\n",
        "    \"summary\": \"<Detailed, actionable summary of overall performance>\",\n",
        "    \"strengths\": [\n",
        "      \"<Strength 1 with justification and example>\",\n",
        "      \"<Strength 2 with justification and example>\",\n",
        "      \"<Strength 3 with justification and example>\"\n",
        "    ],\n",
        "    \"weaknesses\": [\n",
        "      \"<Weakness 1 with advice and example>\",\n",
        "      \"<Weakness 2 with advice and example>\",\n",
        "      \"<Weakness 3 with advice and example>\"\n",
        "    ]\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Output JSON only. No extra text.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --- 4. ƒê·ªäNH NGHƒ®A ·ª®NG D·ª§NG FLASK ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "CORS(\n",
        "    app,\n",
        "    resources={r\"/*\": {\"origins\": [\"http://localhost:5173\"]}},\n",
        "    supports_credentials=True\n",
        ")\n",
        "\n",
        "@app.post(\"/score\")\n",
        "def score_api():\n",
        "    print(\"--- /score API Called ---\")\n",
        "\n",
        "    try:\n",
        "        data = request.get_json(force=True)\n",
        "    except:\n",
        "        return jsonify({\"error\": \"Invalid JSON body\"}), 400\n",
        "\n",
        "    if not data or \"task\" not in data or \"essay\" not in data:\n",
        "        return jsonify({\"error\": \"Must contain 'task' and 'essay'\"}), 400\n",
        "\n",
        "    essay_content = data[\"essay\"]\n",
        "    word_count = len(essay_content.split())\n",
        "\n",
        "    # RULE 1: Essays under 100 words receive a 0 band score\n",
        "    if word_count < 100:\n",
        "        print(f\"‚ö†Ô∏è B√†i lu·∫≠n c√≥ s·ªë l∆∞·ª£ng t·ª´ ({word_count}) d∆∞·ªõi 100 t·ª´. Tr·∫£ v·ªÅ ƒëi·ªÉm 0.\")\n",
        "        return jsonify({\n",
        "            \"task_achievement\": {\n",
        "                \"assessment\": f\"B√†i lu·∫≠n c√≥ s·ªë l∆∞·ª£ng t·ª´ ({word_count} t·ª´) d∆∞·ªõi m·ª©c t·ªëi thi·ªÉu y√™u c·∫ßu (100 t·ª´ ƒë·ªÉ ƒë√°nh gi√°, v√† 250 t·ª´ cho IELTS Writing Task 2). Do ƒë√≥, ƒëi·ªÉm Task Achievement l√† 0.\",\n",
        "                \"suggested_band_score\": \"0\"\n",
        "            },\n",
        "            \"coherence_cohesion\": {\n",
        "                \"assessment\": f\"B√†i lu·∫≠n c√≥ s·ªë l∆∞·ª£ng t·ª´ ({word_count} t·ª´) d∆∞·ªõi m·ª©c t·ªëi thi·ªÉu y√™u c·∫ßu (100 t·ª´ ƒë·ªÉ ƒë√°nh gi√°, v√† 250 t·ª´ cho IELTS Writing Task 2). Do ƒë√≥, ƒëi·ªÉm Coherence and Cohesion l√† 0.\",\n",
        "                \"suggested_band_score\": \"0\"\n",
        "            },\n",
        "            \"lexical_resource\": {\n",
        "                \"assessment\": f\"B√†i lu·∫≠n c√≥ s·ªë l∆∞·ª£ng t·ª´ ({word_count} t·ª´) d∆∞·ªõi m·ª©c t·ªëi thi·ªÉu y√™u c·∫ßu (100 t·ª´ ƒë·ªÉ ƒë√°nh gi√°, v√† 250 t·ª´ cho IELTS Writing Task 2). Do ƒë√≥, ƒëi·ªÉm Lexical Resource l√† 0.\",\n",
        "                \"mistakes_rectified\": [],\n",
        "                \"examples_of_good_vocabulary\": [],\n",
        "                \"suggested_band_score\": \"0\"\n",
        "            },\n",
        "            \"grammatical_range_accuracy\": {\n",
        "                \"assessment\": f\"B√†i lu·∫≠n c√≥ s·ªë l∆∞·ª£ng t·ª´ ({word_count} t·ª´) d∆∞·ªõi m·ª©c t·ªëi thi·ªÉu y√™u c·∫ßu (100 t·ª´ ƒë·ªÉ ƒë√°nh gi√°, v√† 250 t·ª´ cho IELTS Writing Task 2). Do ƒë√≥, ƒëi·ªÉm Grammatical Range and Accuracy l√† 0.\",\n",
        "                \"mistakes_rectified\": [],\n",
        "                \"examples_of_complex_structures\": [],\n",
        "                \"suggested_band_score\": \"0\"\n",
        "            },\n",
        "            \"overall_band_score\": \"0\",\n",
        "            \"feedback\": {\n",
        "                \"summary\": f\"B√†i lu·∫≠n ƒë√£ n·ªôp qu√° ng·∫Øn ({word_count} t·ª´) ƒë·ªÉ ƒë∆∞·ª£c ƒë√°nh gi√° m·ªôt c√°ch c√≥ √Ω nghƒ©a. IELTS Writing Task 2 y√™u c·∫ßu t·ªëi thi·ªÉu 250 t·ª´. M·ªôt b√†i lu·∫≠n d∆∞·ªõi 100 t·ª´ s·∫Ω nh·∫≠n ƒëi·ªÉm 0.\",\n",
        "                \"strengths\": [],\n",
        "                \"weaknesses\": [\n",
        "                    {\n",
        "                        \"original\": f\"ƒê·ªô d√†i b√†i lu·∫≠n ({word_count} t·ª´)\",\n",
        "                        \"correction\": \"B√†i lu·∫≠n n√†y √≠t h∆°n 100 t·ª´ v√† kh√¥ng th·ªÉ ch·∫•m ƒëi·ªÉm. ƒê·ªëi v·ªõi IELTS Writing Task 2, b·∫°n c·∫ßn vi·∫øt √≠t nh·∫•t 250 t·ª´. H√£y luy·ªán t·∫≠p vi·∫øt b√†i lu·∫≠n d√†i h∆°n v√† ƒë·∫ßy ƒë·ªß h∆°n.\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }), 200\n",
        "\n",
        "\n",
        "    prompt = PROMPT.format(task=data[\"task\"], essay=data[\"essay\"])\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    input_length = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    print(\"üß† Generating model response...\")\n",
        "    raw_result_for_debugging = \"\"\n",
        "    try:\n",
        "        with torch.autocast(\"cuda\", dtype=torch.float16):\n",
        "            output = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=1800,\n",
        "                do_sample=False,\n",
        "                repetition_penalty=1.1\n",
        "            )\n",
        "\n",
        "        generated_tokens = output[0][input_length:]\n",
        "        result = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "        raw_result_for_debugging = result\n",
        "\n",
        "        json_start = result.find('{')\n",
        "        json_end = result.rfind('}') + 1\n",
        "\n",
        "        if json_start == -1 or json_end == 0:\n",
        "            raise ValueError(\"Could not find JSON object in model output.\")\n",
        "\n",
        "        json_string = result[json_start:json_end]\n",
        "        json_output = json.loads(json_string)\n",
        "\n",
        "        # RULE 2: Deduct band points for essays between 100 and 249 words\n",
        "        if 100 <= word_count < 150:\n",
        "            words_short = 150 - word_count\n",
        "            deduction_points = (words_short + 19) // 20\n",
        "            deduction_points = min(deduction_points, 3)\n",
        "\n",
        "            if deduction_points > 0:\n",
        "                print(f\"‚ö†Ô∏è √Åp d·ª•ng tr·ª´ {deduction_points} band ƒëi·ªÉm do s·ªë l∆∞·ª£ng t·ª´ kh√¥ng ƒë·ªß.\")\n",
        "                for criterion in [\"task_achievement\", \"coherence_cohesion\", \"lexical_resource\", \"grammatical_range_accuracy\"]:\n",
        "                    current_score = float(json_output[criterion][\"suggested_band_score\"])\n",
        "                    new_score = max(0, current_score - deduction_points)\n",
        "                    json_output[criterion][\"suggested_band_score\"] = f\"{new_score:.1f}\" if new_score % 1 != 0 else f\"{int(new_score)}\"\n",
        "                    json_output[criterion][\"assessment\"] += f\" (ƒêi·ªÉm s·ªë ƒë√£ b·ªã tr·ª´ {deduction_points} band do s·ªë l∆∞·ª£ng t·ª´ kh√¥ng ƒë·ªß).\"\n",
        "\n",
        "                current_overall_score = float(json_output[\"overall_band_score\"])\n",
        "                new_overall_score = max(0, current_overall_score - deduction_points)\n",
        "                json_output[\"overall_band_score\"] = f\"{new_overall_score:.1f}\" if new_overall_score % 1 != 0 else f\"{int(new_overall_score)}\"\n",
        "                json_output[\"feedback\"][\"summary\"] += f\" ƒêi·ªÉm t·ªïng th·ªÉ ƒë√£ b·ªã tr·ª´ {deduction_points} band do s·ªë l∆∞·ª£ng t·ª´ kh√¥ng ƒë·∫°t y√™u c·∫ßu.\"\n",
        "\n",
        "        return jsonify(json_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        print(\"--- RAW MODEL OUTPUT (for debugging) ---\")\n",
        "        print(raw_result_for_debugging)\n",
        "        print(\"--------------------------------------\")\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\n",
        "            \"error\": \"Model output failed\",\n",
        "            \"details\": str(e),\n",
        "            \"raw_output\": raw_result_for_debugging\n",
        "        }), 500\n",
        "\n",
        "# --- 5. CH·∫†Y APP & NGROK ---\n",
        "\n",
        "# Gi·∫£i ph√≥ng c·ªïng 8000\n",
        "!fuser -k 8000/tcp\n",
        "print(\"\\nGi·∫£i ph√≥ng c·ªïng 8000 (n·∫øu c√≥).\")\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"ƒêang kh·ªüi ƒë·ªông Flask trong lu·ªìng n·ªÅn...\")\n",
        "def run_app():\n",
        "    app.run(host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "Thread(target=run_app).start()\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"ƒêang kh·ªüi ƒë·ªông ngrok tunnel...\")\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # THAY TH·∫æ B·∫∞NG TOKEN C·ª¶A B·∫†N\n",
        "    ngrok.set_auth_token(\"359YSz612N8Cj9iWCPAQeaossp0_xgwQztkG5V74JudVncTC\")\n",
        "\n",
        "    public_url_object = ngrok.connect(8000)\n",
        "    public_url = public_url_object.public_url\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ API ƒêANG CH·∫†Y! (API IS RUNNING!)\")\n",
        "    print(f\"üåç URL C√¥ng khai (Public URL): {public_url}\")\n",
        "    print(f\"üëâ Endpoint ƒë·ªÉ ch·∫•m ƒëi·ªÉm: {public_url}/score\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh thi·∫øt l·∫≠p ngrok: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}